{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Dataset for Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = helper.HeartDataset(\"./Heart_disease_cleveland_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80-20 train test split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create the dataloaders\n",
    "train_dl = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dl = DataLoader(test_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = helper.Classifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.MSELoss()\n",
    "lr= 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-05)\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/loss.py:432: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/loss.py:432: UserWarning: Using a target size (torch.Size([13])) that is different to the input size (torch.Size([13, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/1000], loss: 0.429262\n",
      "Epoch[2/1000], loss: 0.208706\n",
      "Epoch[3/1000], loss: 0.331590\n",
      "Epoch[4/1000], loss: 0.319485\n",
      "Epoch[5/1000], loss: 0.427250\n",
      "Epoch[6/1000], loss: 0.455858\n",
      "Epoch[7/1000], loss: 0.181792\n",
      "Epoch[8/1000], loss: 0.312683\n",
      "Epoch[9/1000], loss: 0.307786\n",
      "Epoch[10/1000], loss: 0.251065\n",
      "Epoch[11/1000], loss: 0.344861\n",
      "Epoch[12/1000], loss: 0.293859\n",
      "Epoch[13/1000], loss: 0.268165\n",
      "Epoch[14/1000], loss: 0.246192\n",
      "Epoch[15/1000], loss: 0.229008\n",
      "Epoch[16/1000], loss: 0.277496\n",
      "Epoch[17/1000], loss: 0.174908\n",
      "Epoch[18/1000], loss: 0.314596\n",
      "Epoch[19/1000], loss: 0.277014\n",
      "Epoch[20/1000], loss: 0.318811\n",
      "Epoch[21/1000], loss: 0.341918\n",
      "Epoch[22/1000], loss: 0.362556\n",
      "Epoch[23/1000], loss: 0.321903\n",
      "Epoch[24/1000], loss: 0.340371\n",
      "Epoch[25/1000], loss: 0.382421\n",
      "Epoch[26/1000], loss: 0.378962\n",
      "Epoch[27/1000], loss: 0.329385\n",
      "Epoch[28/1000], loss: 0.356101\n",
      "Epoch[29/1000], loss: 0.322101\n",
      "Epoch[30/1000], loss: 0.307439\n",
      "Epoch[31/1000], loss: 0.329004\n",
      "Epoch[32/1000], loss: 0.344591\n",
      "Epoch[33/1000], loss: 0.378025\n",
      "Epoch[34/1000], loss: 0.337517\n",
      "Epoch[35/1000], loss: 0.307404\n",
      "Epoch[36/1000], loss: 0.294397\n",
      "Epoch[37/1000], loss: 0.307249\n",
      "Epoch[38/1000], loss: 0.370081\n",
      "Epoch[39/1000], loss: 0.263402\n",
      "Epoch[40/1000], loss: 0.358277\n",
      "Epoch[41/1000], loss: 0.290779\n",
      "Epoch[42/1000], loss: 0.343933\n",
      "Epoch[43/1000], loss: 0.432053\n",
      "Epoch[44/1000], loss: 0.364755\n",
      "Epoch[45/1000], loss: 0.273933\n",
      "Epoch[46/1000], loss: 0.331307\n",
      "Epoch[47/1000], loss: 0.409189\n",
      "Epoch[48/1000], loss: 0.419128\n",
      "Epoch[49/1000], loss: 0.310152\n",
      "Epoch[50/1000], loss: 0.358356\n",
      "Epoch[51/1000], loss: 0.393778\n",
      "Epoch[52/1000], loss: 0.386795\n",
      "Epoch[53/1000], loss: 0.413617\n",
      "Epoch[54/1000], loss: 0.418401\n",
      "Epoch[55/1000], loss: 0.416210\n",
      "Epoch[56/1000], loss: 0.341902\n",
      "Epoch[57/1000], loss: 0.405507\n",
      "Epoch[58/1000], loss: 0.348798\n",
      "Epoch[59/1000], loss: 0.350812\n",
      "Epoch[60/1000], loss: 0.365780\n",
      "Epoch[61/1000], loss: 0.286936\n",
      "Epoch[62/1000], loss: 0.351882\n",
      "Epoch[63/1000], loss: 0.362671\n",
      "Epoch[64/1000], loss: 0.401564\n",
      "Epoch[65/1000], loss: 0.350223\n",
      "Epoch[66/1000], loss: 0.251576\n",
      "Epoch[67/1000], loss: 0.322143\n",
      "Epoch[68/1000], loss: 0.366130\n",
      "Epoch[69/1000], loss: 0.430365\n",
      "Epoch[70/1000], loss: 0.353921\n",
      "Epoch[71/1000], loss: 0.403503\n",
      "Epoch[72/1000], loss: 0.346841\n",
      "Epoch[73/1000], loss: 0.376263\n",
      "Epoch[74/1000], loss: 0.389657\n",
      "Epoch[75/1000], loss: 0.401182\n",
      "Epoch[76/1000], loss: 0.401176\n",
      "Epoch[77/1000], loss: 0.402892\n",
      "Epoch[78/1000], loss: 0.400642\n",
      "Epoch[79/1000], loss: 0.387795\n",
      "Epoch[80/1000], loss: 0.355721\n",
      "Epoch[81/1000], loss: 0.408256\n",
      "Epoch[82/1000], loss: 0.367729\n",
      "Epoch[83/1000], loss: 0.400777\n",
      "Epoch[84/1000], loss: 0.406753\n",
      "Epoch[85/1000], loss: 0.426324\n",
      "Epoch[86/1000], loss: 0.359098\n",
      "Epoch[87/1000], loss: 0.395914\n",
      "Epoch[88/1000], loss: 0.327876\n",
      "Epoch[89/1000], loss: 0.354466\n",
      "Epoch[90/1000], loss: 0.384591\n",
      "Epoch[91/1000], loss: 0.384898\n",
      "Epoch[92/1000], loss: 0.396071\n",
      "Epoch[93/1000], loss: 0.354433\n",
      "Epoch[94/1000], loss: 0.385324\n",
      "Epoch[95/1000], loss: 0.347396\n",
      "Epoch[96/1000], loss: 0.376147\n",
      "Epoch[97/1000], loss: 0.361488\n",
      "Epoch[98/1000], loss: 0.295811\n",
      "Epoch[99/1000], loss: 0.317845\n",
      "Epoch[100/1000], loss: 0.364860\n",
      "Epoch[101/1000], loss: 0.439919\n",
      "Epoch[102/1000], loss: 0.356683\n",
      "Epoch[103/1000], loss: 0.397036\n",
      "Epoch[104/1000], loss: 0.396388\n",
      "Epoch[105/1000], loss: 0.377416\n",
      "Epoch[106/1000], loss: 0.348389\n",
      "Epoch[107/1000], loss: 0.307302\n",
      "Epoch[108/1000], loss: 0.453883\n",
      "Epoch[109/1000], loss: 0.348691\n",
      "Epoch[110/1000], loss: 0.392292\n",
      "Epoch[111/1000], loss: 0.384603\n",
      "Epoch[112/1000], loss: 0.391064\n",
      "Epoch[113/1000], loss: 0.361076\n",
      "Epoch[114/1000], loss: 0.373156\n",
      "Epoch[115/1000], loss: 0.382900\n",
      "Epoch[116/1000], loss: 0.357006\n",
      "Epoch[117/1000], loss: 0.358672\n",
      "Epoch[118/1000], loss: 0.376293\n",
      "Epoch[119/1000], loss: 0.360227\n",
      "Epoch[120/1000], loss: 0.378161\n",
      "Epoch[121/1000], loss: 0.366605\n",
      "Epoch[122/1000], loss: 0.403448\n",
      "Epoch[123/1000], loss: 0.423813\n",
      "Epoch[124/1000], loss: 0.369911\n",
      "Epoch[125/1000], loss: 0.312276\n",
      "Epoch[126/1000], loss: 0.405685\n",
      "Epoch[127/1000], loss: 0.432208\n",
      "Epoch[128/1000], loss: 0.374466\n",
      "Epoch[129/1000], loss: 0.350736\n",
      "Epoch[130/1000], loss: 0.303935\n",
      "Epoch[131/1000], loss: 0.371009\n",
      "Epoch[132/1000], loss: 0.395302\n",
      "Epoch[133/1000], loss: 0.297716\n",
      "Epoch[134/1000], loss: 0.349757\n",
      "Epoch[135/1000], loss: 0.360216\n",
      "Epoch[136/1000], loss: 0.400399\n",
      "Epoch[137/1000], loss: 0.290556\n",
      "Epoch[138/1000], loss: 0.412001\n",
      "Epoch[139/1000], loss: 0.362094\n",
      "Epoch[140/1000], loss: 0.371326\n",
      "Epoch[141/1000], loss: 0.284419\n",
      "Epoch[142/1000], loss: 0.306160\n",
      "Epoch[143/1000], loss: 0.319391\n",
      "Epoch[144/1000], loss: 0.341480\n",
      "Epoch[145/1000], loss: 0.393620\n",
      "Epoch[146/1000], loss: 0.338316\n",
      "Epoch[147/1000], loss: 0.350587\n",
      "Epoch[148/1000], loss: 0.379452\n",
      "Epoch[149/1000], loss: 0.381438\n",
      "Epoch[150/1000], loss: 0.402766\n",
      "Epoch[151/1000], loss: 0.390256\n",
      "Epoch[152/1000], loss: 0.237506\n",
      "Epoch[153/1000], loss: 0.406710\n",
      "Epoch[154/1000], loss: 0.421692\n",
      "Epoch[155/1000], loss: 0.356907\n",
      "Epoch[156/1000], loss: 0.314526\n",
      "Epoch[157/1000], loss: 0.363389\n",
      "Epoch[158/1000], loss: 0.372780\n",
      "Epoch[159/1000], loss: 0.360649\n",
      "Epoch[160/1000], loss: 0.411068\n",
      "Epoch[161/1000], loss: 0.394638\n",
      "Epoch[162/1000], loss: 0.298764\n",
      "Epoch[163/1000], loss: 0.394437\n",
      "Epoch[164/1000], loss: 0.334155\n",
      "Epoch[165/1000], loss: 0.264551\n",
      "Epoch[166/1000], loss: 0.364768\n",
      "Epoch[167/1000], loss: 0.332468\n",
      "Epoch[168/1000], loss: 0.398829\n",
      "Epoch[169/1000], loss: 0.375582\n",
      "Epoch[170/1000], loss: 0.412105\n",
      "Epoch[171/1000], loss: 0.396322\n",
      "Epoch[172/1000], loss: 0.392511\n",
      "Epoch[173/1000], loss: 0.365905\n",
      "Epoch[174/1000], loss: 0.429877\n",
      "Epoch[175/1000], loss: 0.406844\n",
      "Epoch[176/1000], loss: 0.395681\n",
      "Epoch[177/1000], loss: 0.393728\n",
      "Epoch[178/1000], loss: 0.421393\n",
      "Epoch[179/1000], loss: 0.405995\n",
      "Epoch[180/1000], loss: 0.423193\n",
      "Epoch[181/1000], loss: 0.371347\n",
      "Epoch[182/1000], loss: 0.387514\n",
      "Epoch[183/1000], loss: 0.389799\n",
      "Epoch[184/1000], loss: 0.354854\n",
      "Epoch[185/1000], loss: 0.396550\n",
      "Epoch[186/1000], loss: 0.323271\n",
      "Epoch[187/1000], loss: 0.447089\n",
      "Epoch[188/1000], loss: 0.326466\n",
      "Epoch[189/1000], loss: 0.352091\n",
      "Epoch[190/1000], loss: 0.407647\n",
      "Epoch[191/1000], loss: 0.404049\n",
      "Epoch[192/1000], loss: 0.384196\n",
      "Epoch[193/1000], loss: 0.352441\n",
      "Epoch[194/1000], loss: 0.446219\n",
      "Epoch[195/1000], loss: 0.379404\n",
      "Epoch[196/1000], loss: 0.359832\n",
      "Epoch[197/1000], loss: 0.368934\n",
      "Epoch[198/1000], loss: 0.401859\n",
      "Epoch[199/1000], loss: 0.450634\n",
      "Epoch[200/1000], loss: 0.366469\n",
      "Epoch[201/1000], loss: 0.422065\n",
      "Epoch[202/1000], loss: 0.343515\n",
      "Epoch[203/1000], loss: 0.254598\n",
      "Epoch[204/1000], loss: 0.397561\n",
      "Epoch[205/1000], loss: 0.425551\n",
      "Epoch[206/1000], loss: 0.390291\n",
      "Epoch[207/1000], loss: 0.372639\n",
      "Epoch[208/1000], loss: 0.401150\n",
      "Epoch[209/1000], loss: 0.389071\n",
      "Epoch[210/1000], loss: 0.394922\n",
      "Epoch[211/1000], loss: 0.401043\n",
      "Epoch[212/1000], loss: 0.401040\n",
      "Epoch[213/1000], loss: 0.400271\n",
      "Epoch[214/1000], loss: 0.341731\n",
      "Epoch[215/1000], loss: 0.398783\n",
      "Epoch[216/1000], loss: 0.408645\n",
      "Epoch[217/1000], loss: 0.399301\n",
      "Epoch[218/1000], loss: 0.345631\n",
      "Epoch[219/1000], loss: 0.333252\n",
      "Epoch[220/1000], loss: 0.382940\n",
      "Epoch[221/1000], loss: 0.400534\n",
      "Epoch[222/1000], loss: 0.354836\n",
      "Epoch[223/1000], loss: 0.384598\n",
      "Epoch[224/1000], loss: 0.410895\n",
      "Epoch[225/1000], loss: 0.395935\n",
      "Epoch[226/1000], loss: 0.451752\n",
      "Epoch[227/1000], loss: 0.364142\n",
      "Epoch[228/1000], loss: 0.387051\n",
      "Epoch[229/1000], loss: 0.362405\n",
      "Epoch[230/1000], loss: 0.334803\n",
      "Epoch[231/1000], loss: 0.319293\n",
      "Epoch[232/1000], loss: 0.406122\n",
      "Epoch[233/1000], loss: 0.394218\n",
      "Epoch[234/1000], loss: 0.393834\n",
      "Epoch[235/1000], loss: 0.376074\n",
      "Epoch[236/1000], loss: 0.417556\n",
      "Epoch[237/1000], loss: 0.415754\n",
      "Epoch[238/1000], loss: 0.460933\n",
      "Epoch[239/1000], loss: 0.418118\n",
      "Epoch[240/1000], loss: 0.307058\n",
      "Epoch[241/1000], loss: 0.395418\n",
      "Epoch[242/1000], loss: 0.398638\n",
      "Epoch[243/1000], loss: 0.388749\n",
      "Epoch[244/1000], loss: 0.420311\n",
      "Epoch[245/1000], loss: 0.394992\n",
      "Epoch[246/1000], loss: 0.379251\n",
      "Epoch[247/1000], loss: 0.437113\n",
      "Epoch[248/1000], loss: 0.455465\n",
      "Epoch[249/1000], loss: 0.426122\n",
      "Epoch[250/1000], loss: 0.432198\n",
      "Epoch[251/1000], loss: 0.373538\n",
      "Epoch[252/1000], loss: 0.423964\n",
      "Epoch[253/1000], loss: 0.397753\n",
      "Epoch[254/1000], loss: 0.435655\n",
      "Epoch[255/1000], loss: 0.362653\n",
      "Epoch[256/1000], loss: 0.395135\n",
      "Epoch[257/1000], loss: 0.430482\n",
      "Epoch[258/1000], loss: 0.373809\n",
      "Epoch[259/1000], loss: 0.371789\n",
      "Epoch[260/1000], loss: 0.391803\n",
      "Epoch[261/1000], loss: 0.423822\n",
      "Epoch[262/1000], loss: 0.421586\n",
      "Epoch[263/1000], loss: 0.343016\n",
      "Epoch[264/1000], loss: 0.359302\n",
      "Epoch[265/1000], loss: 0.366078\n",
      "Epoch[266/1000], loss: 0.474785\n",
      "Epoch[267/1000], loss: 0.363974\n",
      "Epoch[268/1000], loss: 0.378622\n",
      "Epoch[269/1000], loss: 0.350346\n",
      "Epoch[270/1000], loss: 0.354550\n",
      "Epoch[271/1000], loss: 0.407924\n",
      "Epoch[272/1000], loss: 0.367960\n",
      "Epoch[273/1000], loss: 0.385399\n",
      "Epoch[274/1000], loss: 0.412400\n",
      "Epoch[275/1000], loss: 0.375528\n",
      "Epoch[276/1000], loss: 0.396446\n",
      "Epoch[277/1000], loss: 0.273756\n",
      "Epoch[278/1000], loss: 0.323850\n",
      "Epoch[279/1000], loss: 0.402216\n",
      "Epoch[280/1000], loss: 0.433469\n",
      "Epoch[281/1000], loss: 0.420046\n",
      "Epoch[282/1000], loss: 0.276207\n",
      "Epoch[283/1000], loss: 0.391025\n",
      "Epoch[284/1000], loss: 0.330127\n",
      "Epoch[285/1000], loss: 0.348430\n",
      "Epoch[286/1000], loss: 0.434429\n",
      "Epoch[287/1000], loss: 0.401229\n",
      "Epoch[288/1000], loss: 0.388434\n",
      "Epoch[289/1000], loss: 0.357107\n",
      "Epoch[290/1000], loss: 0.412847\n",
      "Epoch[291/1000], loss: 0.342729\n",
      "Epoch[292/1000], loss: 0.430091\n",
      "Epoch[293/1000], loss: 0.385608\n",
      "Epoch[294/1000], loss: 0.365654\n",
      "Epoch[295/1000], loss: 0.443997\n",
      "Epoch[296/1000], loss: 0.415472\n",
      "Epoch[297/1000], loss: 0.436558\n",
      "Epoch[298/1000], loss: 0.352977\n",
      "Epoch[299/1000], loss: 0.360637\n",
      "Epoch[300/1000], loss: 0.401061\n",
      "Epoch[301/1000], loss: 0.329586\n",
      "Epoch[302/1000], loss: 0.347970\n",
      "Epoch[303/1000], loss: 0.344569\n",
      "Epoch[304/1000], loss: 0.400682\n",
      "Epoch[305/1000], loss: 0.412349\n",
      "Epoch[306/1000], loss: 0.417819\n",
      "Epoch[307/1000], loss: 0.431167\n",
      "Epoch[308/1000], loss: 0.443126\n",
      "Epoch[309/1000], loss: 0.405317\n",
      "Epoch[310/1000], loss: 0.406702\n",
      "Epoch[311/1000], loss: 0.359829\n",
      "Epoch[312/1000], loss: 0.360878\n",
      "Epoch[313/1000], loss: 0.374834\n",
      "Epoch[314/1000], loss: 0.403720\n",
      "Epoch[315/1000], loss: 0.397030\n",
      "Epoch[316/1000], loss: 0.430120\n",
      "Epoch[317/1000], loss: 0.473508\n",
      "Epoch[318/1000], loss: 0.413719\n",
      "Epoch[319/1000], loss: 0.398653\n",
      "Epoch[320/1000], loss: 0.346635\n",
      "Epoch[321/1000], loss: 0.248414\n",
      "Epoch[322/1000], loss: 0.464541\n",
      "Epoch[323/1000], loss: 0.469978\n",
      "Epoch[324/1000], loss: 0.400247\n",
      "Epoch[325/1000], loss: 0.392331\n",
      "Epoch[326/1000], loss: 0.450568\n",
      "Epoch[327/1000], loss: 0.359499\n",
      "Epoch[328/1000], loss: 0.314492\n",
      "Epoch[329/1000], loss: 0.412020\n",
      "Epoch[330/1000], loss: 0.395671\n",
      "Epoch[331/1000], loss: 0.375413\n",
      "Epoch[332/1000], loss: 0.426175\n",
      "Epoch[333/1000], loss: 0.426391\n",
      "Epoch[334/1000], loss: 0.472409\n",
      "Epoch[335/1000], loss: 0.486456\n",
      "Epoch[336/1000], loss: 0.395352\n",
      "Epoch[337/1000], loss: 0.383737\n",
      "Epoch[338/1000], loss: 0.458071\n",
      "Epoch[339/1000], loss: 0.160675\n",
      "Epoch[340/1000], loss: 0.329140\n",
      "Epoch[341/1000], loss: 0.391532\n",
      "Epoch[342/1000], loss: 0.399617\n",
      "Epoch[343/1000], loss: 0.444047\n",
      "Epoch[344/1000], loss: 0.366083\n",
      "Epoch[345/1000], loss: 0.372287\n",
      "Epoch[346/1000], loss: 0.394235\n",
      "Epoch[347/1000], loss: 0.293663\n",
      "Epoch[348/1000], loss: 0.416445\n",
      "Epoch[349/1000], loss: 0.391343\n",
      "Epoch[350/1000], loss: 0.454465\n",
      "Epoch[351/1000], loss: 0.435891\n",
      "Epoch[352/1000], loss: 0.397861\n",
      "Epoch[353/1000], loss: 0.235720\n",
      "Epoch[354/1000], loss: 0.314848\n",
      "Epoch[355/1000], loss: 0.442834\n",
      "Epoch[356/1000], loss: 0.389615\n",
      "Epoch[357/1000], loss: 0.382014\n",
      "Epoch[358/1000], loss: 0.399111\n",
      "Epoch[359/1000], loss: 0.394355\n",
      "Epoch[360/1000], loss: 0.446683\n",
      "Epoch[361/1000], loss: 0.456440\n",
      "Epoch[362/1000], loss: 0.419158\n",
      "Epoch[363/1000], loss: 0.424189\n",
      "Epoch[364/1000], loss: 0.419780\n",
      "Epoch[365/1000], loss: 0.353789\n",
      "Epoch[366/1000], loss: 0.416336\n",
      "Epoch[367/1000], loss: 0.316956\n",
      "Epoch[368/1000], loss: 0.402211\n",
      "Epoch[369/1000], loss: 0.366588\n",
      "Epoch[370/1000], loss: 0.415392\n",
      "Epoch[371/1000], loss: 0.373489\n",
      "Epoch[372/1000], loss: 0.365436\n",
      "Epoch[373/1000], loss: 0.381644\n",
      "Epoch[374/1000], loss: 0.418682\n",
      "Epoch[375/1000], loss: 0.403162\n",
      "Epoch[376/1000], loss: 0.331902\n",
      "Epoch[377/1000], loss: 0.360582\n",
      "Epoch[378/1000], loss: 0.400703\n",
      "Epoch[379/1000], loss: 0.365024\n",
      "Epoch[380/1000], loss: 0.379059\n",
      "Epoch[381/1000], loss: 0.385888\n",
      "Epoch[382/1000], loss: 0.391848\n",
      "Epoch[383/1000], loss: 0.395310\n",
      "Epoch[384/1000], loss: 0.391595\n",
      "Epoch[385/1000], loss: 0.386585\n",
      "Epoch[386/1000], loss: 0.358299\n",
      "Epoch[387/1000], loss: 0.422755\n",
      "Epoch[388/1000], loss: 0.311832\n",
      "Epoch[389/1000], loss: 0.388915\n",
      "Epoch[390/1000], loss: 0.376452\n",
      "Epoch[391/1000], loss: 0.297765\n",
      "Epoch[392/1000], loss: 0.471857\n",
      "Epoch[393/1000], loss: 0.376653\n",
      "Epoch[394/1000], loss: 0.387776\n",
      "Epoch[395/1000], loss: 0.459136\n",
      "Epoch[396/1000], loss: 0.410617\n",
      "Epoch[397/1000], loss: 0.401169\n",
      "Epoch[398/1000], loss: 0.342343\n",
      "Epoch[399/1000], loss: 0.415607\n",
      "Epoch[400/1000], loss: 0.381203\n",
      "Epoch[401/1000], loss: 0.428011\n",
      "Epoch[402/1000], loss: 0.388653\n",
      "Epoch[403/1000], loss: 0.375460\n",
      "Epoch[404/1000], loss: 0.387915\n",
      "Epoch[405/1000], loss: 0.434658\n",
      "Epoch[406/1000], loss: 0.359403\n",
      "Epoch[407/1000], loss: 0.376957\n",
      "Epoch[408/1000], loss: 0.344442\n",
      "Epoch[409/1000], loss: 0.412852\n",
      "Epoch[410/1000], loss: 0.369004\n",
      "Epoch[411/1000], loss: 0.369791\n",
      "Epoch[412/1000], loss: 0.414618\n",
      "Epoch[413/1000], loss: 0.369745\n",
      "Epoch[414/1000], loss: 0.341345\n",
      "Epoch[415/1000], loss: 0.390874\n",
      "Epoch[416/1000], loss: 0.400587\n",
      "Epoch[417/1000], loss: 0.392788\n",
      "Epoch[418/1000], loss: 0.433465\n",
      "Epoch[419/1000], loss: 0.372883\n",
      "Epoch[420/1000], loss: 0.275969\n",
      "Epoch[421/1000], loss: 0.430179\n",
      "Epoch[422/1000], loss: 0.393814\n",
      "Epoch[423/1000], loss: 0.406504\n",
      "Epoch[424/1000], loss: 0.363362\n",
      "Epoch[425/1000], loss: 0.434857\n",
      "Epoch[426/1000], loss: 0.433703\n",
      "Epoch[427/1000], loss: 0.462679\n",
      "Epoch[428/1000], loss: 0.413287\n",
      "Epoch[429/1000], loss: 0.432425\n",
      "Epoch[430/1000], loss: 0.358045\n",
      "Epoch[431/1000], loss: 0.373351\n",
      "Epoch[432/1000], loss: 0.358597\n",
      "Epoch[433/1000], loss: 0.412335\n",
      "Epoch[434/1000], loss: 0.382438\n",
      "Epoch[435/1000], loss: 0.372970\n",
      "Epoch[436/1000], loss: 0.359011\n",
      "Epoch[437/1000], loss: 0.294138\n",
      "Epoch[438/1000], loss: 0.390047\n",
      "Epoch[439/1000], loss: 0.405559\n",
      "Epoch[440/1000], loss: 0.406458\n",
      "Epoch[441/1000], loss: 0.447363\n",
      "Epoch[442/1000], loss: 0.400176\n",
      "Epoch[443/1000], loss: 0.349527\n",
      "Epoch[444/1000], loss: 0.439078\n",
      "Epoch[445/1000], loss: 0.375577\n",
      "Epoch[446/1000], loss: 0.347299\n",
      "Epoch[447/1000], loss: 0.389271\n",
      "Epoch[448/1000], loss: 0.370313\n",
      "Epoch[449/1000], loss: 0.374064\n",
      "Epoch[450/1000], loss: 0.383540\n",
      "Epoch[451/1000], loss: 0.403286\n",
      "Epoch[452/1000], loss: 0.439179\n",
      "Epoch[453/1000], loss: 0.420039\n",
      "Epoch[454/1000], loss: 0.401335\n",
      "Epoch[455/1000], loss: 0.390216\n",
      "Epoch[456/1000], loss: 0.386132\n",
      "Epoch[457/1000], loss: 0.386472\n",
      "Epoch[458/1000], loss: 0.369521\n",
      "Epoch[459/1000], loss: 0.445221\n",
      "Epoch[460/1000], loss: 0.418176\n",
      "Epoch[461/1000], loss: 0.333571\n",
      "Epoch[462/1000], loss: 0.401692\n",
      "Epoch[463/1000], loss: 0.431694\n",
      "Epoch[464/1000], loss: 0.389522\n",
      "Epoch[465/1000], loss: 0.327767\n",
      "Epoch[466/1000], loss: 0.413017\n",
      "Epoch[467/1000], loss: 0.408759\n",
      "Epoch[468/1000], loss: 0.395772\n",
      "Epoch[469/1000], loss: 0.400921\n",
      "Epoch[470/1000], loss: 0.390602\n",
      "Epoch[471/1000], loss: 0.391001\n",
      "Epoch[472/1000], loss: 0.436118\n",
      "Epoch[473/1000], loss: 0.408166\n",
      "Epoch[474/1000], loss: 0.414987\n",
      "Epoch[475/1000], loss: 0.396144\n",
      "Epoch[476/1000], loss: 0.257534\n",
      "Epoch[477/1000], loss: 0.409065\n",
      "Epoch[478/1000], loss: 0.445145\n",
      "Epoch[479/1000], loss: 0.439435\n",
      "Epoch[480/1000], loss: 0.333395\n",
      "Epoch[481/1000], loss: 0.414842\n",
      "Epoch[482/1000], loss: 0.373650\n",
      "Epoch[483/1000], loss: 0.410364\n",
      "Epoch[484/1000], loss: 0.339707\n",
      "Epoch[485/1000], loss: 0.385387\n",
      "Epoch[486/1000], loss: 0.356679\n",
      "Epoch[487/1000], loss: 0.397784\n",
      "Epoch[488/1000], loss: 0.381345\n",
      "Epoch[489/1000], loss: 0.397732\n",
      "Epoch[490/1000], loss: 0.386703\n",
      "Epoch[491/1000], loss: 0.435696\n",
      "Epoch[492/1000], loss: 0.408909\n",
      "Epoch[493/1000], loss: 0.369555\n",
      "Epoch[494/1000], loss: 0.357147\n",
      "Epoch[495/1000], loss: 0.477071\n",
      "Epoch[496/1000], loss: 0.415152\n",
      "Epoch[497/1000], loss: 0.418737\n",
      "Epoch[498/1000], loss: 0.421219\n",
      "Epoch[499/1000], loss: 0.459542\n",
      "Epoch[500/1000], loss: 0.348510\n",
      "Epoch[501/1000], loss: 0.407008\n",
      "Epoch[502/1000], loss: 0.435085\n",
      "Epoch[503/1000], loss: 0.449091\n",
      "Epoch[504/1000], loss: 0.421271\n",
      "Epoch[505/1000], loss: 0.419752\n",
      "Epoch[506/1000], loss: 0.411247\n",
      "Epoch[507/1000], loss: 0.396702\n",
      "Epoch[508/1000], loss: 0.487394\n",
      "Epoch[509/1000], loss: 0.383035\n",
      "Epoch[510/1000], loss: 0.435430\n",
      "Epoch[511/1000], loss: 0.387889\n",
      "Epoch[512/1000], loss: 0.384566\n",
      "Epoch[513/1000], loss: 0.363707\n",
      "Epoch[514/1000], loss: 0.425561\n",
      "Epoch[515/1000], loss: 0.292388\n",
      "Epoch[516/1000], loss: 0.407588\n",
      "Epoch[517/1000], loss: 0.376734\n",
      "Epoch[518/1000], loss: 0.337790\n",
      "Epoch[519/1000], loss: 0.403755\n",
      "Epoch[520/1000], loss: 0.435833\n",
      "Epoch[521/1000], loss: 0.412288\n",
      "Epoch[522/1000], loss: 0.428205\n",
      "Epoch[523/1000], loss: 0.376783\n",
      "Epoch[524/1000], loss: 0.390768\n",
      "Epoch[525/1000], loss: 0.361999\n",
      "Epoch[526/1000], loss: 0.379063\n",
      "Epoch[527/1000], loss: 0.413373\n",
      "Epoch[528/1000], loss: 0.379006\n",
      "Epoch[529/1000], loss: 0.452345\n",
      "Epoch[530/1000], loss: 0.386214\n",
      "Epoch[531/1000], loss: 0.420774\n",
      "Epoch[532/1000], loss: 0.428102\n",
      "Epoch[533/1000], loss: 0.400358\n",
      "Epoch[534/1000], loss: 0.427685\n",
      "Epoch[535/1000], loss: 0.434241\n",
      "Epoch[536/1000], loss: 0.427111\n",
      "Epoch[537/1000], loss: 0.416589\n",
      "Epoch[538/1000], loss: 0.419500\n",
      "Epoch[539/1000], loss: 0.373477\n",
      "Epoch[540/1000], loss: 0.423230\n",
      "Epoch[541/1000], loss: 0.392318\n",
      "Epoch[542/1000], loss: 0.414071\n",
      "Epoch[543/1000], loss: 0.322271\n",
      "Epoch[544/1000], loss: 0.457410\n",
      "Epoch[545/1000], loss: 0.407645\n",
      "Epoch[546/1000], loss: 0.411280\n",
      "Epoch[547/1000], loss: 0.315629\n",
      "Epoch[548/1000], loss: 0.312768\n",
      "Epoch[549/1000], loss: 0.385846\n",
      "Epoch[550/1000], loss: 0.417498\n",
      "Epoch[551/1000], loss: 0.421162\n",
      "Epoch[552/1000], loss: 0.466213\n",
      "Epoch[553/1000], loss: 0.381410\n",
      "Epoch[554/1000], loss: 0.369573\n",
      "Epoch[555/1000], loss: 0.359920\n",
      "Epoch[556/1000], loss: 0.433298\n",
      "Epoch[557/1000], loss: 0.425247\n",
      "Epoch[558/1000], loss: 0.324158\n",
      "Epoch[559/1000], loss: 0.340219\n",
      "Epoch[560/1000], loss: 0.408054\n",
      "Epoch[561/1000], loss: 0.361391\n",
      "Epoch[562/1000], loss: 0.335092\n",
      "Epoch[563/1000], loss: 0.371842\n",
      "Epoch[564/1000], loss: 0.300325\n",
      "Epoch[565/1000], loss: 0.406473\n",
      "Epoch[566/1000], loss: 0.419664\n",
      "Epoch[567/1000], loss: 0.342165\n",
      "Epoch[568/1000], loss: 0.357586\n",
      "Epoch[569/1000], loss: 0.423463\n",
      "Epoch[570/1000], loss: 0.401244\n",
      "Epoch[571/1000], loss: 0.370732\n",
      "Epoch[572/1000], loss: 0.343199\n",
      "Epoch[573/1000], loss: 0.414782\n",
      "Epoch[574/1000], loss: 0.400113\n",
      "Epoch[575/1000], loss: 0.352115\n",
      "Epoch[576/1000], loss: 0.407602\n",
      "Epoch[577/1000], loss: 0.417145\n",
      "Epoch[578/1000], loss: 0.400359\n",
      "Epoch[579/1000], loss: 0.435456\n",
      "Epoch[580/1000], loss: 0.377358\n",
      "Epoch[581/1000], loss: 0.424883\n",
      "Epoch[582/1000], loss: 0.417292\n",
      "Epoch[583/1000], loss: 0.426514\n",
      "Epoch[584/1000], loss: 0.368267\n",
      "Epoch[585/1000], loss: 0.446214\n",
      "Epoch[586/1000], loss: 0.399540\n",
      "Epoch[587/1000], loss: 0.392445\n",
      "Epoch[588/1000], loss: 0.361465\n",
      "Epoch[589/1000], loss: 0.408427\n",
      "Epoch[590/1000], loss: 0.317874\n",
      "Epoch[591/1000], loss: 0.405130\n",
      "Epoch[592/1000], loss: 0.348356\n",
      "Epoch[593/1000], loss: 0.422810\n",
      "Epoch[594/1000], loss: 0.369976\n",
      "Epoch[595/1000], loss: 0.447086\n",
      "Epoch[596/1000], loss: 0.432884\n",
      "Epoch[597/1000], loss: 0.318595\n",
      "Epoch[598/1000], loss: 0.375198\n",
      "Epoch[599/1000], loss: 0.432388\n",
      "Epoch[600/1000], loss: 0.365804\n",
      "Epoch[601/1000], loss: 0.387216\n",
      "Epoch[602/1000], loss: 0.368869\n",
      "Epoch[603/1000], loss: 0.406317\n",
      "Epoch[604/1000], loss: 0.486389\n",
      "Epoch[605/1000], loss: 0.350999\n",
      "Epoch[606/1000], loss: 0.461470\n",
      "Epoch[607/1000], loss: 0.502536\n",
      "Epoch[608/1000], loss: 0.389673\n",
      "Epoch[609/1000], loss: 0.365227\n",
      "Epoch[610/1000], loss: 0.423696\n",
      "Epoch[611/1000], loss: 0.388203\n",
      "Epoch[612/1000], loss: 0.381538\n",
      "Epoch[613/1000], loss: 0.322206\n",
      "Epoch[614/1000], loss: 0.409646\n",
      "Epoch[615/1000], loss: 0.394158\n",
      "Epoch[616/1000], loss: 0.429791\n",
      "Epoch[617/1000], loss: 0.248378\n",
      "Epoch[618/1000], loss: 0.388420\n",
      "Epoch[619/1000], loss: 0.428233\n",
      "Epoch[620/1000], loss: 0.408274\n",
      "Epoch[621/1000], loss: 0.473098\n",
      "Epoch[622/1000], loss: 0.391536\n",
      "Epoch[623/1000], loss: 0.390331\n",
      "Epoch[624/1000], loss: 0.381938\n",
      "Epoch[625/1000], loss: 0.435480\n",
      "Epoch[626/1000], loss: 0.390082\n",
      "Epoch[627/1000], loss: 0.380140\n",
      "Epoch[628/1000], loss: 0.310790\n",
      "Epoch[629/1000], loss: 0.364161\n",
      "Epoch[630/1000], loss: 0.376280\n",
      "Epoch[631/1000], loss: 0.400779\n",
      "Epoch[632/1000], loss: 0.436115\n",
      "Epoch[633/1000], loss: 0.410369\n",
      "Epoch[634/1000], loss: 0.401280\n",
      "Epoch[635/1000], loss: 0.363286\n",
      "Epoch[636/1000], loss: 0.378226\n",
      "Epoch[637/1000], loss: 0.447611\n",
      "Epoch[638/1000], loss: 0.419526\n",
      "Epoch[639/1000], loss: 0.357008\n",
      "Epoch[640/1000], loss: 0.349724\n",
      "Epoch[641/1000], loss: 0.293825\n",
      "Epoch[642/1000], loss: 0.390283\n",
      "Epoch[643/1000], loss: 0.429343\n",
      "Epoch[644/1000], loss: 0.411962\n",
      "Epoch[645/1000], loss: 0.394575\n",
      "Epoch[646/1000], loss: 0.405618\n",
      "Epoch[647/1000], loss: 0.348193\n",
      "Epoch[648/1000], loss: 0.365239\n",
      "Epoch[649/1000], loss: 0.408173\n",
      "Epoch[650/1000], loss: 0.409126\n",
      "Epoch[651/1000], loss: 0.343053\n",
      "Epoch[652/1000], loss: 0.341962\n",
      "Epoch[653/1000], loss: 0.371431\n",
      "Epoch[654/1000], loss: 0.414023\n",
      "Epoch[655/1000], loss: 0.393923\n",
      "Epoch[656/1000], loss: 0.357126\n",
      "Epoch[657/1000], loss: 0.382781\n",
      "Epoch[658/1000], loss: 0.420045\n",
      "Epoch[659/1000], loss: 0.478437\n",
      "Epoch[660/1000], loss: 0.406349\n",
      "Epoch[661/1000], loss: 0.398611\n",
      "Epoch[662/1000], loss: 0.417737\n",
      "Epoch[663/1000], loss: 0.433958\n",
      "Epoch[664/1000], loss: 0.387611\n",
      "Epoch[665/1000], loss: 0.360964\n",
      "Epoch[666/1000], loss: 0.439142\n",
      "Epoch[667/1000], loss: 0.413226\n",
      "Epoch[668/1000], loss: 0.373031\n",
      "Epoch[669/1000], loss: 0.449838\n",
      "Epoch[670/1000], loss: 0.337536\n",
      "Epoch[671/1000], loss: 0.334809\n",
      "Epoch[672/1000], loss: 0.394359\n",
      "Epoch[673/1000], loss: 0.431019\n",
      "Epoch[674/1000], loss: 0.421681\n",
      "Epoch[675/1000], loss: 0.346068\n",
      "Epoch[676/1000], loss: 0.444639\n",
      "Epoch[677/1000], loss: 0.289440\n",
      "Epoch[678/1000], loss: 0.398308\n",
      "Epoch[679/1000], loss: 0.385311\n",
      "Epoch[680/1000], loss: 0.450655\n",
      "Epoch[681/1000], loss: 0.459923\n",
      "Epoch[682/1000], loss: 0.444792\n",
      "Epoch[683/1000], loss: 0.389262\n",
      "Epoch[684/1000], loss: 0.430284\n",
      "Epoch[685/1000], loss: 0.391806\n",
      "Epoch[686/1000], loss: 0.256600\n",
      "Epoch[687/1000], loss: 0.358914\n",
      "Epoch[688/1000], loss: 0.415732\n",
      "Epoch[689/1000], loss: 0.306076\n",
      "Epoch[690/1000], loss: 0.320101\n",
      "Epoch[691/1000], loss: 0.325767\n",
      "Epoch[692/1000], loss: 0.430131\n",
      "Epoch[693/1000], loss: 0.373472\n",
      "Epoch[694/1000], loss: 0.431301\n",
      "Epoch[695/1000], loss: 0.322250\n",
      "Epoch[696/1000], loss: 0.409955\n",
      "Epoch[697/1000], loss: 0.337416\n",
      "Epoch[698/1000], loss: 0.443383\n",
      "Epoch[699/1000], loss: 0.306049\n",
      "Epoch[700/1000], loss: 0.429390\n",
      "Epoch[701/1000], loss: 0.414830\n",
      "Epoch[702/1000], loss: 0.453845\n",
      "Epoch[703/1000], loss: 0.378676\n",
      "Epoch[704/1000], loss: 0.438397\n",
      "Epoch[705/1000], loss: 0.424835\n",
      "Epoch[706/1000], loss: 0.348013\n",
      "Epoch[707/1000], loss: 0.376372\n",
      "Epoch[708/1000], loss: 0.242004\n",
      "Epoch[709/1000], loss: 0.452770\n",
      "Epoch[710/1000], loss: 0.416954\n",
      "Epoch[711/1000], loss: 0.435131\n",
      "Epoch[712/1000], loss: 0.357458\n",
      "Epoch[713/1000], loss: 0.349612\n",
      "Epoch[714/1000], loss: 0.428399\n",
      "Epoch[715/1000], loss: 0.416796\n",
      "Epoch[716/1000], loss: 0.417591\n",
      "Epoch[717/1000], loss: 0.250118\n",
      "Epoch[718/1000], loss: 0.434902\n",
      "Epoch[719/1000], loss: 0.398595\n",
      "Epoch[720/1000], loss: 0.407813\n",
      "Epoch[721/1000], loss: 0.353515\n",
      "Epoch[722/1000], loss: 0.401034\n",
      "Epoch[723/1000], loss: 0.361480\n",
      "Epoch[724/1000], loss: 0.368323\n",
      "Epoch[725/1000], loss: 0.450147\n",
      "Epoch[726/1000], loss: 0.391311\n",
      "Epoch[727/1000], loss: 0.389603\n",
      "Epoch[728/1000], loss: 0.420704\n",
      "Epoch[729/1000], loss: 0.423337\n",
      "Epoch[730/1000], loss: 0.386892\n",
      "Epoch[731/1000], loss: 0.400045\n",
      "Epoch[732/1000], loss: 0.359876\n",
      "Epoch[733/1000], loss: 0.423942\n",
      "Epoch[734/1000], loss: 0.406879\n",
      "Epoch[735/1000], loss: 0.391544\n",
      "Epoch[736/1000], loss: 0.454172\n",
      "Epoch[737/1000], loss: 0.392298\n",
      "Epoch[738/1000], loss: 0.417192\n",
      "Epoch[739/1000], loss: 0.383554\n",
      "Epoch[740/1000], loss: 0.272956\n",
      "Epoch[741/1000], loss: 0.342661\n",
      "Epoch[742/1000], loss: 0.349916\n",
      "Epoch[743/1000], loss: 0.344617\n",
      "Epoch[744/1000], loss: 0.352950\n",
      "Epoch[745/1000], loss: 0.375732\n",
      "Epoch[746/1000], loss: 0.384077\n",
      "Epoch[747/1000], loss: 0.388810\n",
      "Epoch[748/1000], loss: 0.386998\n",
      "Epoch[749/1000], loss: 0.382176\n",
      "Epoch[750/1000], loss: 0.438210\n",
      "Epoch[751/1000], loss: 0.437044\n",
      "Epoch[752/1000], loss: 0.422596\n",
      "Epoch[753/1000], loss: 0.372598\n",
      "Epoch[754/1000], loss: 0.401296\n",
      "Epoch[755/1000], loss: 0.366496\n",
      "Epoch[756/1000], loss: 0.405311\n",
      "Epoch[757/1000], loss: 0.408858\n",
      "Epoch[758/1000], loss: 0.432267\n",
      "Epoch[759/1000], loss: 0.355868\n",
      "Epoch[760/1000], loss: 0.385041\n",
      "Epoch[761/1000], loss: 0.394659\n",
      "Epoch[762/1000], loss: 0.431362\n",
      "Epoch[763/1000], loss: 0.397997\n",
      "Epoch[764/1000], loss: 0.390595\n",
      "Epoch[765/1000], loss: 0.357003\n",
      "Epoch[766/1000], loss: 0.243240\n",
      "Epoch[767/1000], loss: 0.424772\n",
      "Epoch[768/1000], loss: 0.439131\n",
      "Epoch[769/1000], loss: 0.437608\n",
      "Epoch[770/1000], loss: 0.368278\n",
      "Epoch[771/1000], loss: 0.374876\n",
      "Epoch[772/1000], loss: 0.376613\n",
      "Epoch[773/1000], loss: 0.407678\n",
      "Epoch[774/1000], loss: 0.402866\n",
      "Epoch[775/1000], loss: 0.384579\n",
      "Epoch[776/1000], loss: 0.303016\n",
      "Epoch[777/1000], loss: 0.417339\n",
      "Epoch[778/1000], loss: 0.465219\n",
      "Epoch[779/1000], loss: 0.368954\n",
      "Epoch[780/1000], loss: 0.426083\n",
      "Epoch[781/1000], loss: 0.388572\n",
      "Epoch[782/1000], loss: 0.441432\n",
      "Epoch[783/1000], loss: 0.345525\n",
      "Epoch[784/1000], loss: 0.439612\n",
      "Epoch[785/1000], loss: 0.377331\n",
      "Epoch[786/1000], loss: 0.353145\n",
      "Epoch[787/1000], loss: 0.459956\n",
      "Epoch[788/1000], loss: 0.337568\n",
      "Epoch[789/1000], loss: 0.410247\n",
      "Epoch[790/1000], loss: 0.358604\n",
      "Epoch[791/1000], loss: 0.358270\n",
      "Epoch[792/1000], loss: 0.393739\n",
      "Epoch[793/1000], loss: 0.367225\n",
      "Epoch[794/1000], loss: 0.411161\n",
      "Epoch[795/1000], loss: 0.311762\n",
      "Epoch[796/1000], loss: 0.343515\n",
      "Epoch[797/1000], loss: 0.353906\n",
      "Epoch[798/1000], loss: 0.404474\n",
      "Epoch[799/1000], loss: 0.371388\n",
      "Epoch[800/1000], loss: 0.337973\n",
      "Epoch[801/1000], loss: 0.440805\n",
      "Epoch[802/1000], loss: 0.369715\n",
      "Epoch[803/1000], loss: 0.369046\n",
      "Epoch[804/1000], loss: 0.404904\n",
      "Epoch[805/1000], loss: 0.423285\n",
      "Epoch[806/1000], loss: 0.377902\n",
      "Epoch[807/1000], loss: 0.342488\n",
      "Epoch[808/1000], loss: 0.455843\n",
      "Epoch[809/1000], loss: 0.397591\n",
      "Epoch[810/1000], loss: 0.334862\n",
      "Epoch[811/1000], loss: 0.407563\n",
      "Epoch[812/1000], loss: 0.385489\n",
      "Epoch[813/1000], loss: 0.422154\n",
      "Epoch[814/1000], loss: 0.429456\n",
      "Epoch[815/1000], loss: 0.409550\n",
      "Epoch[816/1000], loss: 0.375300\n",
      "Epoch[817/1000], loss: 0.397240\n",
      "Epoch[818/1000], loss: 0.416434\n",
      "Epoch[819/1000], loss: 0.313478\n",
      "Epoch[820/1000], loss: 0.363736\n",
      "Epoch[821/1000], loss: 0.408202\n",
      "Epoch[822/1000], loss: 0.393300\n",
      "Epoch[823/1000], loss: 0.390141\n",
      "Epoch[824/1000], loss: 0.373928\n",
      "Epoch[825/1000], loss: 0.348951\n",
      "Epoch[826/1000], loss: 0.459865\n",
      "Epoch[827/1000], loss: 0.375768\n",
      "Epoch[828/1000], loss: 0.454902\n",
      "Epoch[829/1000], loss: 0.395561\n",
      "Epoch[830/1000], loss: 0.388834\n",
      "Epoch[831/1000], loss: 0.416654\n",
      "Epoch[832/1000], loss: 0.353559\n",
      "Epoch[833/1000], loss: 0.382120\n",
      "Epoch[834/1000], loss: 0.392986\n",
      "Epoch[835/1000], loss: 0.365527\n",
      "Epoch[836/1000], loss: 0.414737\n",
      "Epoch[837/1000], loss: 0.322600\n",
      "Epoch[838/1000], loss: 0.352859\n",
      "Epoch[839/1000], loss: 0.459224\n",
      "Epoch[840/1000], loss: 0.415171\n",
      "Epoch[841/1000], loss: 0.444863\n",
      "Epoch[842/1000], loss: 0.424915\n",
      "Epoch[843/1000], loss: 0.413120\n",
      "Epoch[844/1000], loss: 0.398015\n",
      "Epoch[845/1000], loss: 0.379497\n",
      "Epoch[846/1000], loss: 0.420047\n",
      "Epoch[847/1000], loss: 0.394770\n",
      "Epoch[848/1000], loss: 0.461416\n",
      "Epoch[849/1000], loss: 0.442452\n",
      "Epoch[850/1000], loss: 0.436292\n",
      "Epoch[851/1000], loss: 0.396475\n",
      "Epoch[852/1000], loss: 0.391791\n",
      "Epoch[853/1000], loss: 0.364671\n",
      "Epoch[854/1000], loss: 0.411721\n",
      "Epoch[855/1000], loss: 0.332517\n",
      "Epoch[856/1000], loss: 0.369594\n",
      "Epoch[857/1000], loss: 0.406942\n",
      "Epoch[858/1000], loss: 0.425546\n",
      "Epoch[859/1000], loss: 0.400532\n",
      "Epoch[860/1000], loss: 0.405312\n",
      "Epoch[861/1000], loss: 0.397799\n",
      "Epoch[862/1000], loss: 0.387321\n",
      "Epoch[863/1000], loss: 0.293238\n",
      "Epoch[864/1000], loss: 0.400750\n",
      "Epoch[865/1000], loss: 0.369425\n",
      "Epoch[866/1000], loss: 0.174300\n",
      "Epoch[867/1000], loss: 0.357797\n",
      "Epoch[868/1000], loss: 0.403370\n",
      "Epoch[869/1000], loss: 0.409080\n",
      "Epoch[870/1000], loss: 0.414231\n",
      "Epoch[871/1000], loss: 0.366481\n",
      "Epoch[872/1000], loss: 0.378792\n",
      "Epoch[873/1000], loss: 0.418484\n",
      "Epoch[874/1000], loss: 0.456331\n",
      "Epoch[875/1000], loss: 0.373998\n",
      "Epoch[876/1000], loss: 0.427731\n",
      "Epoch[877/1000], loss: 0.412705\n",
      "Epoch[878/1000], loss: 0.395513\n",
      "Epoch[879/1000], loss: 0.320073\n",
      "Epoch[880/1000], loss: 0.421533\n",
      "Epoch[881/1000], loss: 0.418342\n",
      "Epoch[882/1000], loss: 0.363166\n",
      "Epoch[883/1000], loss: 0.400494\n",
      "Epoch[884/1000], loss: 0.394829\n",
      "Epoch[885/1000], loss: 0.382520\n",
      "Epoch[886/1000], loss: 0.443029\n",
      "Epoch[887/1000], loss: 0.420888\n",
      "Epoch[888/1000], loss: 0.422484\n",
      "Epoch[889/1000], loss: 0.414957\n",
      "Epoch[890/1000], loss: 0.260528\n",
      "Epoch[891/1000], loss: 0.364523\n",
      "Epoch[892/1000], loss: 0.344385\n",
      "Epoch[893/1000], loss: 0.377986\n",
      "Epoch[894/1000], loss: 0.325950\n",
      "Epoch[895/1000], loss: 0.415845\n",
      "Epoch[896/1000], loss: 0.440752\n",
      "Epoch[897/1000], loss: 0.412232\n",
      "Epoch[898/1000], loss: 0.364243\n",
      "Epoch[899/1000], loss: 0.414225\n",
      "Epoch[900/1000], loss: 0.426268\n",
      "Epoch[901/1000], loss: 0.375055\n",
      "Epoch[902/1000], loss: 0.447098\n",
      "Epoch[903/1000], loss: 0.453058\n",
      "Epoch[904/1000], loss: 0.306893\n",
      "Epoch[905/1000], loss: 0.301075\n",
      "Epoch[906/1000], loss: 0.319918\n",
      "Epoch[907/1000], loss: 0.336890\n",
      "Epoch[908/1000], loss: 0.343543\n",
      "Epoch[909/1000], loss: 0.419409\n",
      "Epoch[910/1000], loss: 0.374704\n",
      "Epoch[911/1000], loss: 0.487828\n",
      "Epoch[912/1000], loss: 0.405499\n",
      "Epoch[913/1000], loss: 0.419968\n",
      "Epoch[914/1000], loss: 0.338932\n",
      "Epoch[915/1000], loss: 0.394854\n",
      "Epoch[916/1000], loss: 0.386000\n",
      "Epoch[917/1000], loss: 0.407252\n",
      "Epoch[918/1000], loss: 0.401643\n",
      "Epoch[919/1000], loss: 0.377154\n",
      "Epoch[920/1000], loss: 0.422310\n",
      "Epoch[921/1000], loss: 0.330659\n",
      "Epoch[922/1000], loss: 0.370218\n",
      "Epoch[923/1000], loss: 0.356411\n",
      "Epoch[924/1000], loss: 0.415367\n",
      "Epoch[925/1000], loss: 0.410316\n",
      "Epoch[926/1000], loss: 0.449139\n",
      "Epoch[927/1000], loss: 0.382488\n",
      "Epoch[928/1000], loss: 0.441021\n",
      "Epoch[929/1000], loss: 0.326474\n",
      "Epoch[930/1000], loss: 0.430193\n",
      "Epoch[931/1000], loss: 0.410832\n",
      "Epoch[932/1000], loss: 0.379139\n",
      "Epoch[933/1000], loss: 0.362382\n",
      "Epoch[934/1000], loss: 0.449332\n",
      "Epoch[935/1000], loss: 0.327528\n",
      "Epoch[936/1000], loss: 0.398893\n",
      "Epoch[937/1000], loss: 0.422130\n",
      "Epoch[938/1000], loss: 0.332339\n",
      "Epoch[939/1000], loss: 0.309712\n",
      "Epoch[940/1000], loss: 0.382587\n",
      "Epoch[941/1000], loss: 0.296567\n",
      "Epoch[942/1000], loss: 0.411936\n",
      "Epoch[943/1000], loss: 0.383356\n",
      "Epoch[944/1000], loss: 0.393337\n",
      "Epoch[945/1000], loss: 0.397913\n",
      "Epoch[946/1000], loss: 0.387455\n",
      "Epoch[947/1000], loss: 0.425595\n",
      "Epoch[948/1000], loss: 0.224614\n",
      "Epoch[949/1000], loss: 0.450118\n",
      "Epoch[950/1000], loss: 0.435106\n",
      "Epoch[951/1000], loss: 0.412691\n",
      "Epoch[952/1000], loss: 0.429341\n",
      "Epoch[953/1000], loss: 0.391691\n",
      "Epoch[954/1000], loss: 0.411074\n",
      "Epoch[955/1000], loss: 0.383256\n",
      "Epoch[956/1000], loss: 0.420448\n",
      "Epoch[957/1000], loss: 0.383839\n",
      "Epoch[958/1000], loss: 0.436735\n",
      "Epoch[959/1000], loss: 0.481582\n",
      "Epoch[960/1000], loss: 0.392274\n",
      "Epoch[961/1000], loss: 0.438644\n",
      "Epoch[962/1000], loss: 0.390971\n",
      "Epoch[963/1000], loss: 0.452481\n",
      "Epoch[964/1000], loss: 0.432330\n",
      "Epoch[965/1000], loss: 0.416096\n",
      "Epoch[966/1000], loss: 0.419242\n",
      "Epoch[967/1000], loss: 0.414880\n",
      "Epoch[968/1000], loss: 0.336685\n",
      "Epoch[969/1000], loss: 0.341331\n",
      "Epoch[970/1000], loss: 0.454653\n",
      "Epoch[971/1000], loss: 0.286261\n",
      "Epoch[972/1000], loss: 0.292237\n",
      "Epoch[973/1000], loss: 0.369409\n",
      "Epoch[974/1000], loss: 0.467111\n",
      "Epoch[975/1000], loss: 0.308171\n",
      "Epoch[976/1000], loss: 0.377230\n",
      "Epoch[977/1000], loss: 0.341006\n",
      "Epoch[978/1000], loss: 0.405337\n",
      "Epoch[979/1000], loss: 0.412119\n",
      "Epoch[980/1000], loss: 0.427089\n",
      "Epoch[981/1000], loss: 0.391982\n",
      "Epoch[982/1000], loss: 0.313984\n",
      "Epoch[983/1000], loss: 0.408466\n",
      "Epoch[984/1000], loss: 0.402367\n",
      "Epoch[985/1000], loss: 0.422963\n",
      "Epoch[986/1000], loss: 0.361092\n",
      "Epoch[987/1000], loss: 0.417032\n",
      "Epoch[988/1000], loss: 0.458398\n",
      "Epoch[989/1000], loss: 0.446662\n",
      "Epoch[990/1000], loss: 0.300975\n",
      "Epoch[991/1000], loss: 0.392137\n",
      "Epoch[992/1000], loss: 0.408983\n",
      "Epoch[993/1000], loss: 0.413139\n",
      "Epoch[994/1000], loss: 0.374382\n",
      "Epoch[995/1000], loss: 0.400667\n",
      "Epoch[996/1000], loss: 0.459176\n",
      "Epoch[997/1000], loss: 0.312490\n",
      "Epoch[998/1000], loss: 0.283762\n",
      "Epoch[999/1000], loss: 0.419628\n",
      "Epoch[1000/1000], loss: 0.357106\n"
     ]
    }
   ],
   "source": [
    "for ep in range(epochs):\n",
    "    for i, (batch, batch_labels) in enumerate(train_dl):\n",
    "        model.train()\n",
    "        batch = batch.to(device)\n",
    "        batch_labels = batch_labels.unsqueeze(-1).to(device)\n",
    "\n",
    "        output = model(batch)\n",
    "        #print(output)\n",
    "        #print(batch_labels.shape)\n",
    "        #print(output.shape)\n",
    "        \n",
    "        loss = loss_function(output, batch_labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    for batch, batch_labels in test_dl:\n",
    "        batch = batch.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "\n",
    "        output = model(batch)\n",
    "        #print(output)\n",
    "        loss = loss_function(output, batch_labels)\n",
    "    print('Epoch[{}/{}], loss: {:.6f}'.format(ep + 1, epochs, loss.data.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Accuracy on overall dataset: 0.7392739273927392\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "accuracy = 0\n",
    "for i in range(len(dataset)):\n",
    "    id = \"Incorrect\"\n",
    "    data, label = dataset[i]\n",
    "\n",
    "    data = data.to(device)\n",
    "    label = label.to(device)\n",
    "    \n",
    "    output = model(data)\n",
    "    if(int(output[0]) == label):\n",
    "        accuracy += 1\n",
    "        id = \"Correct\"\n",
    "    print(\"Label: {}\\t|Model Guess: {}\\t| {}\".format(label, int(output[0]), id))\n",
    "print(\"Accuracy on overall dataset: \" + str(accuracy/len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 1\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 1.0\t|Model Guess: 0\t| Incorrect\n",
      "Label: 0.0\t|Model Guess: 0\t| Correct\n",
      "Accuracy on Unseen(test) data: 0.6885245901639344\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy = 0\n",
    "for i in range(len(test_dataset)):\n",
    "    id = \"Incorrect\"\n",
    "    data, label = test_dataset[i]\n",
    "\n",
    "    data = data.to(device)\n",
    "    label = label.to(device)\n",
    "    \n",
    "    output = model(data)\n",
    "    if(int(output[0]) == label):\n",
    "        accuracy += 1\n",
    "        id = \"Correct\"\n",
    "    print(\"Label: {}\\t|Model Guess: {}\\t| {}\".format(label, int(output[0]), id))\n",
    "print(\"Accuracy on Unseen(test) data: \" + str(accuracy/len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
